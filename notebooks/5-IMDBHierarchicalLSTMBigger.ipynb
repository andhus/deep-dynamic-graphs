{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# boilerplate\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.Session()\n",
    "import tensorflow_fold as td"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Define Hierachical LSTM NNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andershuss/.virtualenvs/tensorflow-fold/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py:91: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "def chr_enum(c):\n",
    "    \"\"\"map all common characters to [1...94] any other to 0\"\"\"\n",
    "    enum = ord(c) - ord(' ')\n",
    "    return enum if 0 < enum <= 94 else 0\n",
    "\n",
    "def GetLastState():\n",
    "    \"\"\"Composition of blocks that gets last state vector from LSTM output\"\"\"\n",
    "    return td.GetItem(1) >> td.GetItem(1)\n",
    "\n",
    "def CascadingRNN(cell, rnn_name=None):\n",
    "    \"\"\"Returns a concatenation of input and output state sequence of RNN(cell)\n",
    "    \"\"\"\n",
    "    return td.AllOf(\n",
    "        td.Identity(),\n",
    "        td.RNN(cell, name=rnn_name) >> td.GetItem(0),\n",
    "    ) >> td.Zip() >> td.Map(td.Concat())\n",
    "\n",
    "char_cell = td.ScopedLayer(tf.contrib.rnn.BasicLSTMCell(num_units=64), 'char_cell')\n",
    "word_cell_1 = td.ScopedLayer(tf.contrib.rnn.BasicLSTMCell(num_units=128), 'word_cell_1')\n",
    "word_cell_2 = td.ScopedLayer(tf.contrib.rnn.BasicLSTMCell(num_units=128), 'word_cell_2')\n",
    "\n",
    "word_vector = (\n",
    "    td.InputTransform(lambda word: [chr_enum(c) for c in word]) >>\n",
    "    td.Map(\n",
    "        td.Scalar('int32') >>\n",
    "        td.Function(td.Embedding(95, 8, mod_inputs=False))\n",
    "    ) >>\n",
    "    td.RNN(char_cell) >> GetLastState()\n",
    ")\n",
    "\n",
    "sentence_vector = (\n",
    "    td.InputTransform(lambda text: text.split(' ')) >>\n",
    "    td.Map(word_vector) >>\n",
    "    CascadingRNN(word_cell_1) >> td.RNN(word_cell_2) >> GetLastState()\n",
    ")\n",
    "\n",
    "text_to_logits = sentence_vector >> td.FC(1, activation=None)\n",
    "\n",
    "target = td.Vector(1)\n",
    "\n",
    "compiler = td.Compiler.create((text_to_logits, target))\n",
    "[logits, labels] = compiler.output_tensors\n",
    "loss = tf.losses.sigmoid_cross_entropy(labels, logits)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, 'resources/IMDBHierarchicalLSTMBiggerParams/model.ckpt')\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def get_sentiment(text):\n",
    "    return sigmoid(text_to_logits.eval(text, session=sess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Test some sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.2936632], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment('I would never watch it again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "queries = [\n",
    "    'it was ok',\n",
    "    'it was great',\n",
    "    'it was a disappointment',\n",
    "    'it was a great disappointment',\n",
    "    'I would never watch it again',\n",
    "    'I would watch it again',\n",
    "    'it was booring',\n",
    "    'this doesn\\'t really mean anything',\n",
    "    'this does really mean something'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it was ok: [ 0.84210473]\n",
      "it was great: [ 0.99832338]\n",
      "it was a disappointment: [ 0.01001158]\n",
      "it was a great disappointment: [ 0.13792171]\n",
      "I would never watch it again: [ 0.2936632]\n",
      "I would watch it again: [ 0.79767078]\n",
      "it was booring: [ 0.07158819]\n",
      "this doesn't really mean anything: [ 0.02003623]\n",
      "this does really mean something: [ 0.80717897]\n"
     ]
    }
   ],
   "source": [
    "for query in queries:\n",
    "    print('{}: {}'.format(query, get_sentiment(query)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from tffold_additions.imdb.dataloader import IMDBDataLoader\n",
    "test_dl = IMDBDataLoader('/home/andershuss/Data/aclImdb/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch = train_dl.get_epoch_iterator(batch_size=16)\n",
    "test_feed_dicts = [compiler.build_feed_dict(next(epoch)) for _ in range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probas_pred = tf.nn.sigmoid(logits)\n",
    "labels_pred = tf.cast(probas_pred > 0.5, 'float32')\n",
    "matches = tf.cast(tf.equal(labels_pred, labels), 'float32')\n",
    "n_matches = tf.reduce_sum(matches)\n",
    "accuracy = tf.reduce_mean(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_score = np.mean([sess.run(accuracy, fd) for fd in test_feed_dicts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89687502"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
