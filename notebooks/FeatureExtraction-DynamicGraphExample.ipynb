{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Feature extraction from sequences with various types of input using TF-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# boilerplate\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "import tensorflow_fold as td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "RNN_FEATURE_SIZE = 4\n",
    "A_SIZE = 3\n",
    "B_SIZE = 5\n",
    "\n",
    "input_sequence = [\n",
    "    {'type': 'A', 'data': [1, 2, 3]},\n",
    "    {'type': 'B', 'data': [5, 4, 3, 2, 1]},\n",
    "    {'type': 'A', 'data': [3, 2, 1]},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'data': [1, 2, 3], 'type': 'A'},\n",
       " {'data': [5, 4, 3, 2, 1], 'type': 'B'},\n",
       " {'data': [3, 2, 1], 'type': 'A'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_from_A = td.Vector(A_SIZE) >> td.FC(RNN_FEATURE_SIZE)\n",
    "feature_from_B = td.Vector(B_SIZE) >> td.FC(RNN_FEATURE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.23814273,  0.        ,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_from_A.eval(input_sequence[0]['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#feature_from_A.eval(input_sequence[1]['data'])  # fails since it gets the wrong size of input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data dependent path through computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature = td.OneOf(\n",
    "    key_fn=lambda x: x['type'],\n",
    "    case_blocks={\n",
    "        'A': td.GetItem('data') >> feature_from_A,\n",
    "        'B': td.GetItem('data') >> feature_from_B\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.23814273,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
       " array([ 1.76643121,  0.        ,  0.58830833,  0.        ], dtype=float32),\n",
       " array([ 2.72293854,  0.        ,  0.        ,  0.0422411 ], dtype=float32)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[feature.eval(input_) for input_  in input_sequence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling of arbitrary length sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_sequence = td.Map(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.23814273,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
       " array([ 1.76643121,  0.        ,  0.58830833,  0.        ], dtype=float32),\n",
       " array([ 2.72293854,  0.        ,  0.        ,  0.0422411 ], dtype=float32)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_sequence.eval(input_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Feed Features to RNN..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lstm_cell = td.ScopedLayer(\n",
    "    tf.contrib.rnn.BasicLSTMCell(num_units=16),\n",
    "    'lstm_cell'\n",
    ")\n",
    "lstm_output = feature_sequence >> td.RNN(lstm_cell, name='lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([-0.01530655, -0.01208504, -0.01433548, -0.00552036, -0.00320932,\n",
       "         -0.0082042 , -0.00801775, -0.00635356,  0.01204611, -0.01278908,\n",
       "          0.00692911,  0.00645362, -0.00973393,  0.00959304, -0.00497879,\n",
       "          0.01523228], dtype=float32),\n",
       "  array([-0.17736126, -0.12461913, -0.13674751, -0.02024776, -0.02674744,\n",
       "         -0.03523384, -0.06648903, -0.0595339 ,  0.06722662, -0.08778674,\n",
       "          0.08348105,  0.06476323, -0.09577341,  0.11191335, -0.04952551,\n",
       "          0.11275347], dtype=float32),\n",
       "  array([-0.32331112, -0.24803369, -0.22155015, -0.05607499, -0.06755898,\n",
       "         -0.08475923, -0.13961571, -0.12053503,  0.10680307, -0.11922057,\n",
       "          0.15261184,  0.14180364, -0.18945561,  0.2370128 , -0.10396434,\n",
       "          0.21951388], dtype=float32)],\n",
       " (array([-0.59799623, -0.43577787, -0.58478981, -0.10034901, -0.10941851,\n",
       "         -0.25983173, -0.21727414, -0.21551225,  0.24989481, -0.34144625,\n",
       "          0.33057427,  0.22788048, -0.39905494,  0.45745587, -0.17932983,\n",
       "          0.53661668], dtype=float32),\n",
       "  array([-0.32331112, -0.24803369, -0.22155015, -0.05607499, -0.06755898,\n",
       "         -0.08475923, -0.13961571, -0.12053503,  0.10680307, -0.11922057,\n",
       "          0.15261184,  0.14180364, -0.18945561,  0.2370128 , -0.10396434,\n",
       "          0.21951388], dtype=float32)))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_output.eval(input_sequence)\n",
    "# Format:\n",
    "# (\n",
    "#    [state_0, ... state_T],\n",
    "#    (cell_T, state_T)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "NOTE: When we run block.eval(input) input should only be \"one sample\" (not a batch). However at training time we will feed data in (mini-) batches and fold will handle the variable input types and variable input sequence lenght between samples - _data dependent dynamic graph_ - and will also try to group operations together to actuall carry out computations \"batch wise\" - _dynamic batching_\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
